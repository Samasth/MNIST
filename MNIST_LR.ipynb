{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST-LR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samasth/MNIST/blob/master/MNIST_LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "EtEYcrlt58we",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IpwC3YG36Ckm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_h = img_w = 28             # MNIST images are 28x28\n",
        "img_size_flat = img_h * img_w  # 28x28=784, the total number of pixels\n",
        "n_classes = 10                 # Number of classes, one class per digit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JX_5UzMX6LJd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(mode='train'):\n",
        "    \"\"\"\n",
        "    Function to (download and) load the MNIST data\n",
        "    :param mode: train or test\n",
        "    :return: images and the corresponding labels\n",
        "    \"\"\"\n",
        "    old_v = tf.logging.get_verbosity()\n",
        "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "    from tensorflow.examples.tutorials.mnist import input_data\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "    if mode == 'train':\n",
        "        x_train, y_train, x_valid, y_valid = mnist.train.images, mnist.train.labels, \\\n",
        "                                             mnist.validation.images, mnist.validation.labels\n",
        "        return x_train, y_train, x_valid, y_valid\n",
        "    elif mode == 'test':\n",
        "        x_test, y_test = mnist.test.images, mnist.test.labels\n",
        "    return x_test, y_test\n",
        "\n",
        "\n",
        "def randomize(x, y):\n",
        "    \"\"\" Randomizes the order of data samples and their corresponding labels\"\"\"\n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    shuffled_x = x[permutation, :]\n",
        "    shuffled_y = y[permutation]\n",
        "    return shuffled_x, shuffled_y\n",
        "\n",
        "\n",
        "def get_next_batch(x, y, start, end):\n",
        "    x_batch = x[start:end]\n",
        "    y_batch = y[start:end]\n",
        "    return x_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F9PD73zu6X3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e1885d55-8544-4147-8603-996b91bd2b5f"
      },
      "cell_type": "code",
      "source": [
        "# Load MNIST data\n",
        "x_train, y_train, x_valid, y_valid = load_data(mode='train')\n",
        "print(\"Size of:\")\n",
        "print(\"- Training-set:\\t\\t{}\".format(len(y_train)))\n",
        "print(\"- Validation-set:\\t{}\".format(len(y_valid)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Size of:\n",
            "- Training-set:\t\t55000\n",
            "- Validation-set:\t5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k2OSpWg66oe5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0c4747b0-5a04-4586-ef62-68258860943c"
      },
      "cell_type": "code",
      "source": [
        "print('x_train:\\t{}'.format(x_train.shape))\n",
        "print('y_train:\\t{}'.format(y_train.shape))\n",
        "print('x_train:\\t{}'.format(x_valid.shape))\n",
        "print('y_valid:\\t{}'.format(y_valid.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train:\t(55000, 784)\n",
            "y_train:\t(55000, 10)\n",
            "x_train:\t(5000, 784)\n",
            "y_valid:\t(5000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wwCq3JhD9U1J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "837a0e23-8aab-46c6-af11-c7879145986e"
      },
      "cell_type": "code",
      "source": [
        "y_valid[:5, :]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "7mqkrEpx9bnZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "epochs = 10             # Total number of training epochs\n",
        "batch_size = 100        # Training batch size\n",
        "display_freq = 100      # Frequency of displaying the training results\n",
        "learning_rate = 0.001   # The optimization initial learning rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2I4fbTal9jSx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weight_variable(shape):\n",
        "    \"\"\"\n",
        "    Create a weight variable with appropriate initialization\n",
        "    :param name: weight name\n",
        "    :param shape: weight shape\n",
        "    :return: initialized weight variable\n",
        "    \"\"\"\n",
        "    initer = tf.truncated_normal_initializer(stddev=0.01)\n",
        "    return tf.get_variable('W',\n",
        "                           dtype=tf.float32,\n",
        "                           shape=shape,\n",
        "                           initializer=initer)\n",
        "\n",
        "\n",
        "def bias_variable(shape):\n",
        "    \"\"\"\n",
        "    Create a bias variable with appropriate initialization\n",
        "    :param name: bias variable name\n",
        "    :param shape: bias variable shape\n",
        "    :return: initialized bias variable\n",
        "    \"\"\"\n",
        "    initial = tf.constant(0., shape=shape, dtype=tf.float32)\n",
        "    return tf.get_variable('b',\n",
        "                           dtype=tf.float32,\n",
        "                           initializer=initial)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D5jCljvC9p8h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create the graph for the linear model\n",
        "# Placeholders for inputs (x) and outputs(y)\n",
        "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='X')\n",
        "y = tf.placeholder(tf.float32, shape=[None, n_classes], name='Y')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AP1ihy2i974A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create weight matrix initialized randomely from N~(0, 0.01)\n",
        "W = weight_variable(shape=[img_size_flat, n_classes])\n",
        "\n",
        "# Create bias vector initialized as zero\n",
        "b = bias_variable(shape=[n_classes])\n",
        "\n",
        "output_logits = tf.matmul(x, W) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fMryiEJD9_14",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the loss function, optimizer, and accuracy\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output_logits), name='loss')\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(loss)\n",
        "correct_prediction = tf.equal(tf.argmax(output_logits, 1), tf.argmax(y, 1), name='correct_pred')\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
        "\n",
        "# Model predictions\n",
        "cls_prediction = tf.argmax(output_logits, axis=1, name='predictions')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xBsiEFsj-H-I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating the op for initializing all variables\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wZw7TuVX-Vm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        },
        "outputId": "402bee3b-480c-4495-d612-56a7eaebf719"
      },
      "cell_type": "code",
      "source": [
        "# Create an interactive session (to keep the session in the other cells)\n",
        "sess = tf.InteractiveSession()\n",
        "# Initialize all variables\n",
        "sess.run(init)\n",
        "# Number of training iterations in each epoch\n",
        "num_tr_iter = int(len(y_train) / batch_size)\n",
        "for epoch in range(epochs):\n",
        "    print('Training epoch: {}'.format(epoch + 1))\n",
        "    # Randomly shuffle the training data at the beginning of each epoch \n",
        "    x_train, y_train = randomize(x_train, y_train)\n",
        "    for iteration in range(num_tr_iter):\n",
        "        start = iteration * batch_size\n",
        "        end = (iteration + 1) * batch_size\n",
        "        x_batch, y_batch = get_next_batch(x_train, y_train, start, end)\n",
        "\n",
        "        # Run optimization op (backprop)\n",
        "        feed_dict_batch = {x: x_batch, y: y_batch}\n",
        "        sess.run(optimizer, feed_dict=feed_dict_batch)\n",
        "\n",
        "        if iteration % display_freq == 0:\n",
        "            # Calculate and display the batch loss and accuracy\n",
        "            loss_batch, acc_batch = sess.run([loss, accuracy],\n",
        "                                             feed_dict=feed_dict_batch)\n",
        "\n",
        "            print(\"iter {0:3d}:\\t Loss={1:.2f},\\tTraining Accuracy={2:.01%}\".\n",
        "                  format(iteration, loss_batch, acc_batch))\n",
        "\n",
        "    # Run validation after every epoch\n",
        "    feed_dict_valid = {x: x_valid[:1000], y: y_valid[:1000]}\n",
        "    loss_valid, acc_valid = sess.run([loss, accuracy], feed_dict=feed_dict_valid)\n",
        "    print('---------------------------------------------------------')\n",
        "    print(\"Epoch: {0}, validation loss: {1:.2f}, validation accuracy: {2:.01%}\".\n",
        "          format(epoch + 1, loss_valid, acc_valid))\n",
        "    print('---------------------------------------------------------')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training epoch: 1\n",
            "iter   0:\t Loss=2.25,\tTraining Accuracy=28.0%\n",
            "iter 100:\t Loss=0.92,\tTraining Accuracy=78.0%\n",
            "iter 200:\t Loss=0.48,\tTraining Accuracy=91.0%\n",
            "iter 300:\t Loss=0.46,\tTraining Accuracy=88.0%\n",
            "iter 400:\t Loss=0.32,\tTraining Accuracy=93.0%\n",
            "iter 500:\t Loss=0.41,\tTraining Accuracy=91.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 1, validation loss: 0.41, validation accuracy: 88.1%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 2\n",
            "iter   0:\t Loss=0.38,\tTraining Accuracy=91.0%\n",
            "iter 100:\t Loss=0.37,\tTraining Accuracy=92.0%\n",
            "iter 200:\t Loss=0.35,\tTraining Accuracy=90.0%\n",
            "iter 300:\t Loss=0.31,\tTraining Accuracy=92.0%\n",
            "iter 400:\t Loss=0.32,\tTraining Accuracy=93.0%\n",
            "iter 500:\t Loss=0.35,\tTraining Accuracy=90.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 2, validation loss: 0.35, validation accuracy: 89.6%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 3\n",
            "iter   0:\t Loss=0.33,\tTraining Accuracy=91.0%\n",
            "iter 100:\t Loss=0.31,\tTraining Accuracy=91.0%\n",
            "iter 200:\t Loss=0.32,\tTraining Accuracy=93.0%\n",
            "iter 300:\t Loss=0.29,\tTraining Accuracy=89.0%\n",
            "iter 400:\t Loss=0.35,\tTraining Accuracy=89.0%\n",
            "iter 500:\t Loss=0.32,\tTraining Accuracy=92.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 3, validation loss: 0.32, validation accuracy: 89.9%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 4\n",
            "iter   0:\t Loss=0.16,\tTraining Accuracy=96.0%\n",
            "iter 100:\t Loss=0.16,\tTraining Accuracy=97.0%\n",
            "iter 200:\t Loss=0.44,\tTraining Accuracy=89.0%\n",
            "iter 300:\t Loss=0.22,\tTraining Accuracy=92.0%\n",
            "iter 400:\t Loss=0.22,\tTraining Accuracy=94.0%\n",
            "iter 500:\t Loss=0.28,\tTraining Accuracy=91.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 4, validation loss: 0.31, validation accuracy: 90.8%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 5\n",
            "iter   0:\t Loss=0.31,\tTraining Accuracy=95.0%\n",
            "iter 100:\t Loss=0.24,\tTraining Accuracy=90.0%\n",
            "iter 200:\t Loss=0.39,\tTraining Accuracy=91.0%\n",
            "iter 300:\t Loss=0.39,\tTraining Accuracy=85.0%\n",
            "iter 400:\t Loss=0.28,\tTraining Accuracy=91.0%\n",
            "iter 500:\t Loss=0.16,\tTraining Accuracy=96.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 5, validation loss: 0.30, validation accuracy: 91.2%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 6\n",
            "iter   0:\t Loss=0.27,\tTraining Accuracy=91.0%\n",
            "iter 100:\t Loss=0.27,\tTraining Accuracy=92.0%\n",
            "iter 200:\t Loss=0.29,\tTraining Accuracy=93.0%\n",
            "iter 300:\t Loss=0.13,\tTraining Accuracy=97.0%\n",
            "iter 400:\t Loss=0.27,\tTraining Accuracy=92.0%\n",
            "iter 500:\t Loss=0.43,\tTraining Accuracy=89.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 6, validation loss: 0.29, validation accuracy: 92.1%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 7\n",
            "iter   0:\t Loss=0.11,\tTraining Accuracy=99.0%\n",
            "iter 100:\t Loss=0.20,\tTraining Accuracy=96.0%\n",
            "iter 200:\t Loss=0.41,\tTraining Accuracy=88.0%\n",
            "iter 300:\t Loss=0.25,\tTraining Accuracy=93.0%\n",
            "iter 400:\t Loss=0.12,\tTraining Accuracy=98.0%\n",
            "iter 500:\t Loss=0.33,\tTraining Accuracy=93.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 7, validation loss: 0.29, validation accuracy: 91.2%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 8\n",
            "iter   0:\t Loss=0.42,\tTraining Accuracy=91.0%\n",
            "iter 100:\t Loss=0.27,\tTraining Accuracy=93.0%\n",
            "iter 200:\t Loss=0.25,\tTraining Accuracy=91.0%\n",
            "iter 300:\t Loss=0.25,\tTraining Accuracy=91.0%\n",
            "iter 400:\t Loss=0.26,\tTraining Accuracy=92.0%\n",
            "iter 500:\t Loss=0.26,\tTraining Accuracy=94.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 8, validation loss: 0.29, validation accuracy: 91.3%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 9\n",
            "iter   0:\t Loss=0.26,\tTraining Accuracy=94.0%\n",
            "iter 100:\t Loss=0.24,\tTraining Accuracy=92.0%\n",
            "iter 200:\t Loss=0.14,\tTraining Accuracy=96.0%\n",
            "iter 300:\t Loss=0.36,\tTraining Accuracy=85.0%\n",
            "iter 400:\t Loss=0.20,\tTraining Accuracy=94.0%\n",
            "iter 500:\t Loss=0.17,\tTraining Accuracy=97.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 9, validation loss: 0.29, validation accuracy: 91.6%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 10\n",
            "iter   0:\t Loss=0.31,\tTraining Accuracy=92.0%\n",
            "iter 100:\t Loss=0.20,\tTraining Accuracy=93.0%\n",
            "iter 200:\t Loss=0.22,\tTraining Accuracy=93.0%\n",
            "iter 300:\t Loss=0.25,\tTraining Accuracy=93.0%\n",
            "iter 400:\t Loss=0.31,\tTraining Accuracy=91.0%\n",
            "iter 500:\t Loss=0.28,\tTraining Accuracy=92.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 10, validation loss: 0.28, validation accuracy: 91.3%\n",
            "---------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lSovooOc-d85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "338fcaf4-336d-4335-d126-892555632215"
      },
      "cell_type": "code",
      "source": [
        "# Test the network after training\n",
        "# Accuracy\n",
        "x_test, y_test = load_data(mode='test')\n",
        "feed_dict_test = {x: x_test[:1000], y: y_test[:1000]}\n",
        "loss_test, acc_test = sess.run([loss, accuracy], feed_dict=feed_dict_test)\n",
        "print('---------------------------------------------------------')\n",
        "print(\"Test loss: {0:.2f}, test accuracy: {1:.01%}\".format(loss_test, acc_test))\n",
        "print('---------------------------------------------------------')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "---------------------------------------------------------\n",
            "Test loss: 0.27, test accuracy: 91.9%\n",
            "---------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XDNkuyvL-yDp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}